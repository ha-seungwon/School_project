{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Suppress LightGBM info messages\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Read the training and test data\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('testset.csv')\n",
    "\n",
    "train_df=train_df.fillna(0)\n",
    "test_df=test_df.fillna(0)\n",
    "categorical_columns = [\"Gender\", \"V17\", \"V19\"]\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    train_df[column] = label_encoder.fit_transform(train_df[column])\n",
    "    test_df[column] = label_encoder.transform(test_df[column])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in train_df.columns:\n",
    "    \n",
    "    target_columns=i\n",
    "    sns.boxplot(x='class', y=target_columns, data=train_df)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel(f'{target_columns} Feature Value')\n",
    "    plt.title('Box Plot by Class')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define categorical columns for label encoding\n",
    "categorical_columns = [\"Gender\", \"V17\", \"V19\"]\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "for column in categorical_columns:\n",
    "    train_df[column] = label_encoder.fit_transform(train_df[column])\n",
    "    test_df[column] = label_encoder.transform(test_df[column])\n",
    "\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = train_df.drop(columns=['class'])\n",
    "y = train_df['class']\n",
    "y = y.replace({'N': 0, 'Y': 1})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "xgboost_col= ['V5', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V18', 'V19', 'V22']\n",
    "\n",
    "\n",
    "xgb_cls = XGBClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_test1 = {\n",
    " 'max_depth': range(3, 10, 3),\n",
    " 'min_child_weight': range(1, 6, 2)\n",
    "}\n",
    "\n",
    "# Define your XGBClassifier and GridSearchCV\n",
    "xgb = XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=2019,\n",
    "    objective='binary:logistic'  # You missed this parameter\n",
    ")\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "gsearch1 = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_test1,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV on your data\n",
    "gsearch1.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the results\n",
    "results = gsearch1.cv_results_\n",
    "best_params = gsearch1.best_params_\n",
    "best_score = gsearch1.best_score_\n",
    "\n",
    "print(\"Grid Search CV Results:\", results)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_test2 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "\n",
    "# Define your XGBClassifier and GridSearchCV\n",
    "xgb = XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=9,#fin\n",
    "    min_child_weight=1,#fin\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=2019,\n",
    "    objective='binary:logistic'  # You missed this parameter\n",
    ")\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "gsearch2 = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_test2,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV on your data\n",
    "gsearch2.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the results\n",
    "results = gsearch2.cv_results_\n",
    "best_params = gsearch2.best_params_\n",
    "best_score = gsearch2.best_score_\n",
    "\n",
    "print(\"Grid Search CV Results:\", results)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "# Define your XGBClassifier and GridSearchCV\n",
    "xgb = XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=9,#fin\n",
    "    min_child_weight=1,#fin\n",
    "    gamma=0.3,#fin\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=2019,\n",
    "    objective='binary:logistic'  # You missed this parameter\n",
    ")\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "gsearch3 = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_test3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV on your data\n",
    "gsearch3.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the results\n",
    "results = gsearch3.cv_results_\n",
    "best_params = gsearch3.best_params_\n",
    "best_score = gsearch3.best_score_\n",
    "\n",
    "print(\"Grid Search CV Results:\", results)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/100.0 for i in range(40,80)],\n",
    "}\n",
    "# Define your XGBClassifier and GridSearchCV\n",
    "xgb = XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=9,#fin\n",
    "    min_child_weight=1,#fin\n",
    "    gamma=0.3,#fin\n",
    "    subsample=0.9, #fin\n",
    "    colsample_bytree=0.9,#fin\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=2019,\n",
    "    objective='binary:logistic'  # You missed this parameter\n",
    ")\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "gsearch4 = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_test4,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV on your data\n",
    "gsearch4.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the results\n",
    "results = gsearch4.cv_results_\n",
    "best_params = gsearch4.best_params_\n",
    "best_score = gsearch4.best_score_\n",
    "\n",
    "print(\"Grid Search CV Results:\", results)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test5 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "\n",
    "# Define your XGBClassifier and GridSearchCV\n",
    "xgb = XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=9,#fin\n",
    "    min_child_weight=1,#fin\n",
    "    gamma=0.3,#fin\n",
    "    subsample=0.78, #fin\n",
    "    colsample_bytree=0.9,#fin\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=2019,\n",
    "    objective='binary:logistic'  # You missed this parameter\n",
    ")\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "gsearch5 = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_test5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV on your data\n",
    "gsearch5.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the results\n",
    "results = gsearch5.cv_results_\n",
    "best_params = gsearch5.best_params_\n",
    "best_score = gsearch5.best_score_\n",
    "\n",
    "print(\"Grid Search CV Results:\", results)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test6 = {\n",
    " 'learning_rate':[0.1,0.01,0.001,0.2,0.3,0.05,0.07,0.02,0.005]\n",
    "}\n",
    "\n",
    "# Define your XGBClassifier and GridSearchCV\n",
    "xgb = XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=9,#fin\n",
    "    min_child_weight=1,#fin\n",
    "    gamma=0.3,#fin\n",
    "    subsample=0.78, #fin\n",
    "    colsample_bytree=0.9,#fin\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=2019,\n",
    "    objective='binary:logistic',  # You missed this parameter\n",
    "    reg_alpha=1e-5\n",
    ")\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "gsearch6 = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_test6,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV on your data\n",
    "gsearch6.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the results\n",
    "results = gsearch6.cv_results_\n",
    "best_params = gsearch6.best_params_\n",
    "best_score = gsearch6.best_score_\n",
    "\n",
    "print(\"Grid Search CV Results:\", results)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test6 = {\n",
    " 'learning_rate':[0.005,0.006,0.007,0.008,0.009,0.01,0.004,0.003]\n",
    "}\n",
    "\n",
    "# Define your XGBClassifier and GridSearchCV\n",
    "xgb = XGBClassifier(\n",
    "    learning_rate=0.008,\n",
    "    n_estimators=1000,\n",
    "    max_depth=9,#fin\n",
    "    min_child_weight=1,#fin\n",
    "    gamma=0.3,#fin\n",
    "    subsample=0.78, #fin\n",
    "    colsample_bytree=0.9,#fin\n",
    "    nthread=-1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=2019,\n",
    "    objective='binary:logistic',  # You missed this parameter\n",
    "    reg_alpha=1e-5\n",
    ")\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "gsearch6 = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_test6,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV on your data\n",
    "gsearch6.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the results\n",
    "results = gsearch6.cv_results_\n",
    "best_params = gsearch6.best_params_\n",
    "best_score = gsearch6.best_score_\n",
    "\n",
    "print(\"Grid Search CV Results:\", results)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "param_test = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # Learning rate\n",
    "    'n_estimators': [100, 500, 1000],  # Number of boosting rounds\n",
    "    'max_depth': range(3, 10, 3),  # Tree depth\n",
    "    'min_child_weight': range(1, 6, 2),  # Min child weight\n",
    "    'gamma': [0, 0.1, 0.2],  # Regularization term\n",
    "    'subsample': [0.7, 0.8, 0.9],  # Subsample ratio\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9]  # Feature subsampling ratio\n",
    "}\n",
    "\n",
    "# Create the XGBoost classifier\n",
    "xgb = XGBClassifier(\n",
    "    seed=2019,\n",
    "    objective='binary:logistic',\n",
    "    nthread=-1\n",
    ")\n",
    "\n",
    "# Create GridSearchCV object\n",
    "gsearch = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_test,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV on your data\n",
    "gsearch.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the results\n",
    "results = gsearch.cv_results_\n",
    "best_params = gsearch.best_params_\n",
    "best_score = gsearch.best_score_\n",
    "\n",
    "print(\"Grid Search CV Results:\", results)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "param_dist = {\n",
    "    'learning_rate': [random.uniform(0.01, 0.2) for _ in range(10)],  # Learning rate\n",
    "    'n_estimators': [random.randint(100, 1000) for _ in range(10)],  # Number of boosting rounds\n",
    "    'max_depth': [random.randint(3, 10) for _ in range(10)],  # Tree depth\n",
    "    'min_child_weight': [random.randint(1, 6) for _ in range(10)],  # Min child weight\n",
    "    'gamma': [random.uniform(0, 0.2) for _ in range(10)],  # Regularization term\n",
    "    'subsample': [random.uniform(0.7, 0.9) for _ in range(10)],  # Subsample ratio\n",
    "    'colsample_bytree': [random.uniform(0.7, 0.9) for _ in range(10)]  # Feature subsampling ratio\n",
    "}\n",
    "\n",
    "# Create the XGBoost classifier\n",
    "xgb = XGBClassifier(\n",
    "    seed=random.randint(1, 1000),  # Random seed\n",
    "    objective='binary:logistic',\n",
    "    nthread=-1\n",
    ")\n",
    "\n",
    "# Create RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  # Number of random combinations to try\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV on your data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the results\n",
    "results = random_search.cv_results_\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(\"Randomized Search CV Results:\", results)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
