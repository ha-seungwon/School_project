{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   category  mcv  alkphos  sgpt  sgot  gammagt  drinks\n",
      "0         0   85       64    59    32       23     0.0\n",
      "1         0   86       54    33    16       54     0.0\n",
      "2         0   91       78    34    24       36     0.0\n",
      "3         0   87       70    12    28       10     0.0\n",
      "4         0   98       55    13    17       17     0.0\n",
      "Index(['category', 'mcv', 'alkphos', 'sgpt', 'sgot', 'gammagt', 'drinks'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd \n",
    "import pydot# need to install# prepare the iris dataset\n",
    "df = pd.read_csv('liver.csv')\n",
    "print(df.head())\n",
    "print(df.columns)   # column names\n",
    "df_X= df.loc[:, df.columns!= 'category']\n",
    "df_y= df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y= train_test_split(df_X, df_y, test_size=0.3,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  DecisionTreeClassifier(random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=1234)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=1234)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=1234)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Train accuracy : 0.5767634854771784\n",
      "Test accuracy : 0.5576923076923077\n",
      "2\n",
      "Train accuracy : 0.6929460580912863\n",
      "Test accuracy : 0.6538461538461539\n",
      "3\n",
      "Train accuracy : 0.7385892116182573\n",
      "Test accuracy : 0.6730769230769231\n",
      "5\n",
      "Train accuracy : 0.8672199170124482\n",
      "Test accuracy : 0.6923076923076923\n",
      "6\n",
      "Train accuracy : 0.9087136929460581\n",
      "Test accuracy : 0.6634615384615384\n",
      "7\n",
      "Train accuracy : 0.9294605809128631\n",
      "Test accuracy : 0.7019230769230769\n",
      "8\n",
      "Train accuracy : 0.9585062240663901\n",
      "Test accuracy : 0.6826923076923077\n",
      "10\n",
      "Train accuracy : 0.9875518672199171\n",
      "Test accuracy : 0.6538461538461539\n"
     ]
    }
   ],
   "source": [
    "input_list=[1,2,3,5,6,7,8,10]\n",
    "for i in input_list:\n",
    "    print(i)\n",
    "    model =  DecisionTreeClassifier(max_depth=i, random_state=1234)\n",
    "    # Train the model using the training sets\n",
    "    model.fit(train_X, train_y)# performance evaluation\n",
    "    print('Train accuracy :', model.score(train_X, train_y))\n",
    "    print('Test accuracy :', model.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 0.7385892116182573\n",
      "Test accuracy : 0.7596153846153846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[41, 23],\n",
       "       [14, 26]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=svm.SVC(kernel='poly')\n",
    "model.fit(train_X,train_y)\n",
    "print('Train accuracy :', model.score(train_X, train_y))\n",
    "print('Test accuracy :', model.score(test_X, test_y))\n",
    "\n",
    "\n",
    "pred_y-model.predict(test_X)\n",
    "confusion_matrix(test_y,pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/haseung-won/Desktop/학교/4-1/딥러닝/Cloud-Deep_learning_class/chap5/main.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/haseung-won/Desktop/%ED%95%99%EA%B5%90/4-1/%EB%94%A5%EB%9F%AC%EB%8B%9D/Cloud-Deep_learning_class/chap5/main.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1234\u001b[39m)\u001b[39m# Train the model using the training sets\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/haseung-won/Desktop/%ED%95%99%EA%B5%90/4-1/%EB%94%A5%EB%9F%AC%EB%8B%9D/Cloud-Deep_learning_class/chap5/main.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mfit(train_X, train_y)\u001b[39m# performance evaluation\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/haseung-won/Desktop/%ED%95%99%EA%B5%90/4-1/%EB%94%A5%EB%9F%AC%EB%8B%9D/Cloud-Deep_learning_class/chap5/main.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain accuracy :\u001b[39m\u001b[39m'\u001b[39m, model\u001b[39m.\u001b[39mscore(train_X, train_y))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=50, random_state=1234)# Train the model using the training sets\n",
    "model.fit(train_X, train_y)# performance evaluation\n",
    "print('Train accuracy :', model.score(train_X, train_y))\n",
    "print('Test accuracy :', model.score(test_X, test_y))\n",
    "pred_y= model.predict(test_X)\n",
    "confusion_matrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
=======
   "execution_count": 2,
>>>>>>> feebc9e6ebacf72349e62a5297b1a43ddaa6ae0d
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   pregnant  768 non-null    int64  \n",
      " 1   glucose   768 non-null    int64  \n",
      " 2   pressure  768 non-null    int64  \n",
      " 3   triceps   768 non-null    int64  \n",
      " 4   insulin   768 non-null    int64  \n",
      " 5   mass      768 non-null    float64\n",
      " 6   pedigree  768 non-null    float64\n",
      " 7   age       768 non-null    int64  \n",
      " 8   diabetes  768 non-null    object \n",
      "dtypes: float64(2), int64(6), object(1)\n",
      "memory usage: 54.1+ KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd \n",
    "import pydot# need to install# prepare the iris dataset\n",
    "df=pd.read_csv('PimaIndiansDiabetes.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "#Decisiontree,SVM,randomforest,xgboost\n",
    "\n",
    "df_X= df.loc[:, df.columns!= 'diabetes']\n",
    "df_y= df['diabetes']\n",
    "train_X, test_X, train_y, test_y= train_test_split(df_X, df_y, test_size=0.3,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Algorithm: Decision Tree]\n",
      "Train accuracy : 0.9106145251396648\n",
      "Test accuracy : 0.7186147186147186\n",
      "[Algorithm: RandomForestClassifier]\n",
      "Train accuracy : 0.9646182495344506\n",
      "Test accuracy : 0.7532467532467533\n",
      "[Algorithm: SVM]\n",
      "Train accuracy : 0.7821229050279329\n",
      "Test accuracy : 0.7575757575757576\n",
      "[Algorithm: Xgboost]\n",
      "Train accuracy : 0.8417132216014898\n",
      "Test accuracy : 0.7445887445887446\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "Decisiontree_para={'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
    "Randomforest_para={'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
    "SVC_para= {'C': 1, 'degree': 2, 'kernel': 'linear'}\n",
    "xgb_para= {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
    "\n",
    "\n",
    "model1=DecisionTreeClassifier(**Decisiontree_para)\n",
    "model2=RandomForestClassifier(**Randomforest_para)\n",
    "model3=svm.SVC(**SVC_para)\n",
    "model4=xgb.XGBClassifier(**xgb_para)\n",
    "\n",
    "\n",
    "model_list=[model1,model2,model3,model4]\n",
    "model_names=[\"Decision Tree\",\"RandomForestClassifier\",\"SVM\",\"Xgboost\"]\n",
    "\n",
    "\n",
    "for indx,model in enumerate(model_list):\n",
    "    print(f\"[Algorithm: {model_names[indx]}]\")\n",
    "   \n",
    "    if model_names[indx] == \"Xgboost\":\n",
    "        \n",
    "        pd.get_dummies(test_y)\n",
    "        model.fit(train_X,pd.get_dummies(train_y))\n",
    "        print('Train accuracy :', model.score(train_X, pd.get_dummies(train_y)))\n",
    "        print('Test accuracy :', model.score(test_X, pd.get_dummies(test_y)))\n",
    "    else:\n",
    "\n",
    "        model.fit(train_X,train_y)\n",
    "        print('Train accuracy :', model.score(train_X, train_y))\n",
    "        print('Test accuracy :', model.score(test_X, test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "Train accuracy: 0.9068901303538175\n",
      "Test accuracy: 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(train_X, train_y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "print('Best Parameters:', best_params)\n",
    "print('Train accuracy:', best_model.score(train_X, train_y))\n",
    "print('Test accuracy:', best_model.score(test_X, test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Train accuracy: 0.9608938547486033\n",
      "Test accuracy: 0.7445887445887446\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(train_X, train_y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "print('Best Parameters:', best_params)\n",
    "print('Train accuracy:', best_model.score(train_X, train_y))\n",
    "print('Test accuracy:', best_model.score(test_X, test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'degree': 2, 'kernel': 'linear'}\n",
      "Train accuracy: 0.7821229050279329\n",
      "Test accuracy: 0.7575757575757576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'degree': [2, 3, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(svm.SVC(), param_grid, cv=5)\n",
    "grid_search.fit(train_X, train_y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "print('Best Parameters:', best_params)\n",
    "print('Train accuracy:', best_model.score(train_X, train_y))\n",
    "print('Test accuracy:', best_model.score(test_X, test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300}\n",
      "Train accuracy: 0.8417132216014898\n",
      "Test accuracy: 0.7445887445887446\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(xgb.XGBClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(train_X, pd.get_dummies(train_y))\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "print('Best Parameters:', best_params)\n",
    "print('Train accuracy:', best_model.score(train_X, pd.get_dummies(train_y)))\n",
    "print('Test accuracy:', best_model.score(test_X, pd.get_dummies(test_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for Decision Tree:\n",
      "{'criterion': 'gini', 'max_depth': 30, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "Train accuracy: 0.8672199170124482\n",
      "Test accuracy: 0.7115384615384616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a Decision Tree Classifier\n",
    "model1 = DecisionTreeClassifier()\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(model1, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(train_X, train_y)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters for Decision Tree:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model1 = grid_search.best_estimator_\n",
    "best_model1.fit(train_X, train_y)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = best_model1.score(train_X, train_y)\n",
    "test_accuracy = best_model1.score(test_X, test_y)\n",
    "print('Train accuracy:', train_accuracy)\n",
    "print('Test accuracy:', test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for Random Forest:\n",
      "{'max_depth': 20, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Train accuracy: 0.941908713692946\n",
      "Test accuracy: 0.7980769230769231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "model2 = RandomForestClassifier()\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(model2, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(train_X, train_y)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters for Random Forest:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model2 = grid_search.best_estimator_\n",
    "best_model2.fit(train_X, train_y)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = best_model2.score(train_X, train_y)\n",
    "test_accuracy = best_model2.score(test_X, test_y)\n",
    "print('Train accuracy:', train_accuracy)\n",
    "print('Test accuracy:', test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for XGBoost:\n",
      "{'colsample_bytree': 1.0, 'gamma': 0.1, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 50, 'subsample': 0.8}\n",
      "Train accuracy: 0.8796680497925311\n",
      "Test accuracy: 0.75\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create an SVM Classifier\n",
    "model3 = SVC()\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'degree': [2, 3, 4],\n",
    "    'gamma': ['scale', 'auto'] + [0.001, 0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(model3, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(train_X, train_y)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters for SVM:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model3 = grid_search.best_estimator_\n",
    "best_model3.fit(train_X, train_y)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = best_model3.score(train_X, train_y)\n",
    "test_accuracy = best_model3.score(test_X, test_y)\n",
    "print('Train accuracy:', train_accuracy)\n",
    "print('Test accuracy:', test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create an XGBoost Classifier\n",
    "model4 = xgb.XGBClassifier()\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(model4, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(train_X, train_y)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters for XGBoost:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model4 = grid_search.best_estimator_\n",
    "best_model4.fit(train_X, train_y)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = best_model4.score(train_X, train_y)\n",
    "test_accuracy = best_model4.score(test_X, test_y)\n",
    "print('Train accuracy:', train_accuracy)\n",
    "print('Test accuracy:', test_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
